# trend_tracker.py (v5.1 - Security Hardened)

# --- å°å…¥æ‰€æœ‰å‡½å¼åº« ---
import pandas as pd
import gspread
from gspread_dataframe import set_with_dataframe
import json
import feedparser
from datetime import datetime
import time
import smtplib
import ssl
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import os
import google.generativeai as genai
import html # <<< NEW: å°å…¥ html å‡½å¼åº«ç”¨æ–¼è½‰ç¾©

# --- è¨­å®šæ‰€æœ‰å…¨åŸŸè®Šæ•¸ ---
SHEET_NAME_DASHBOARD = "æœ€æ–°è¶¨å‹¢å„€è¡¨æ¿"
SHEET_NAME_LOG = "å®Œæ•´æ­·å²æ—¥èªŒ"
CNA_FEEDS = { 'æ”¿æ²»': 'https://feeds.feedburner.com/rsscna/politics', 'åœ‹éš›': 'https://feeds.feedburner.com/rsscna/intworld', 'å…©å²¸': 'https://feeds.feedburner.com/rsscna/mainland', 'ç”¢ç¶“è­‰åˆ¸': 'https://feeds.feedburner.com/rsscna/finance', 'ç§‘æŠ€': 'https://feeds.feedburner.com/rsscna/technology', 'ç”Ÿæ´»': 'https://feeds.feedburner.com/rsscna/lifehealth', 'ç¤¾æœƒ': 'https://feeds.feedburner.com/rsscna/social', 'åœ°æ–¹': 'https://feeds.feedburner.com/rsscna/local', 'æ–‡åŒ–': 'https://feeds.feedburner.com/rsscna/culture'}
UNINTERESTING_KEYWORDS = ['ä»Šå½©', 'å¤§æ¨‚é€', 'ç™¼ç¥¨', 'å¨åŠ›å½©', 'æ¨‚é€å½©']
GEMINI_MODEL_NAME = 'gemini-1.5-pro-latest'

# --- è®€å–é‡‘é‘°ä¸¦æˆæ¬Š (GitHub Actions ç‰ˆæœ¬) ---
try:
    gcp_key_str = os.environ['GCP_SA_KEY']
    creds_dict = json.loads(gcp_key_str)
    sheet_id = os.environ['G_SHEET_ID']
    sender_email = os.environ['EMAIL_SENDER']
    receiver_email = os.environ['EMAIL_RECEIVER']
    email_password = os.environ['EMAIL_SENDER_APP_PASSWORD']
    gemini_api_key = os.environ['GEMINI_API_KEY']
    gemini_prompt_template = os.environ['GEMINI_PROMPT']
    print("âœ… æ‰€æœ‰å¯†é‘°å¾ç’°å¢ƒè®Šæ•¸è®€å–æˆåŠŸã€‚")
except KeyError as e:
    # <<< MODIFIED: ä¸ç›´æ¥æš´éœ² eï¼Œå› ç‚º e çš„å…§å®¹ (é‡‘é‘°å) ä¹Ÿæ˜¯ä¸€ç¨®è³‡è¨Šæ´©éœ² >>>
    print(f"âŒ è®€å–ç’°å¢ƒè®Šæ•¸å¤±æ•—ï¼è«‹ç¢ºèª GitHub Secrets å·²è¨­å®šã€‚ç¼ºå°‘å¿…è¦çš„é‡‘é‘°ã€‚")
    raise

# --- è¨­å®š Gemini API ---
genai.configure(api_key=gemini_api_key)


# --- NEW: å®‰å…¨æ€§è¼”åŠ©å‡½å¼ ---
def sanitize_error_message(error_msg: any) -> str:
    """æ¸…ç†éŒ¯èª¤ä¿¡æ¯ï¼Œç§»é™¤å¯èƒ½çš„æ•æ„Ÿæ•¸æ“šã€‚"""
    sanitized = str(error_msg)
    # é€™è£¡å¯ä»¥æ·»åŠ æ›´å¤šéœ€è¦éæ¿¾çš„æ¨¡å¼
    patterns_to_remove = [r'AIza[A-Za-z0-9_-]{35}']
    for pattern in patterns_to_remove:
        sanitized = re.sub(pattern, '[REDACTED]', sanitized)
    return sanitized

def escape_html(text: str) -> str:
    """å°æ’å…¥HTMLçš„æ–‡æœ¬é€²è¡Œè½‰ç¾©ï¼Œé˜²æ­¢XSSæ”»æ“Šã€‚"""
    return html.escape(str(text))


# --- å®šç¾©æ‰€æœ‰è¼”åŠ©å‡½å¼ ---
def write_df_to_worksheet(spreadsheet, sheet_name, df, title_text):
    try:
        worksheet = spreadsheet.worksheet(sheet_name)
        worksheet.clear()
    except gspread.WorksheetNotFound:
        worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=len(df)+5, cols=len(df.columns)+1)
    worksheet.update('A1', [[title_text]], value_input_option='USER_ENTERED')
    worksheet.format('A1:G1', {'textFormat': {'bold': True, 'fontSize': 12}})
    set_with_dataframe(worksheet, df, row=3, col=1, include_index=False, resize=True)
    print(f"âœ… æˆåŠŸå°‡è³‡æ–™å¯«å…¥å·¥ä½œè¡¨ '{sheet_name}' (å„€è¡¨æ¿æ¨¡å¼)ã€‚")

def append_df_to_worksheet(spreadsheet, sheet_name, df):
    try:
        worksheet = spreadsheet.worksheet(sheet_name)
    except gspread.WorksheetNotFound:
        worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=len(df.columns)+1)
        worksheet.append_row(df.columns.values.tolist())
    worksheet.append_rows(df.values.tolist())
    print(f"âœ… æˆåŠŸå°‡è³‡æ–™é™„åŠ åˆ°å·¥ä½œè¡¨ '{sheet_name}' (æ—¥èªŒæ¨¡å¼)ã€‚")

def fetch_all_cna_news(feed_urls):
    print("--- [éšæ®µä¸€] æ­£åœ¨é å…ˆæŠ“å–æ‰€æœ‰ä¸­å¤®ç¤¾ RSS Feeds ---")
    all_articles = []
    for category, url in feed_urls.items():
        try:
            feed = feedparser.parse(url)
            if feed.bozo: print(f"    - [è­¦å‘Š] Feed '{category}' æ ¼å¼å¯èƒ½ä¸å®Œæ•´æˆ–æœ‰èª¤ã€‚")
            for entry in feed.entries:
                if hasattr(entry, 'title') and hasattr(entry, 'link'):
                    article_title = entry.title
                    if not any(keyword in article_title for keyword in UNINTERESTING_KEYWORDS):
                        all_articles.append({'title': article_title, 'summary': entry.get('summary', ''), 'link': entry.link})
        except Exception as e:
            # <<< MODIFIED: ä½¿ç”¨æ¸…ç†å‡½å¼ >>>
            print(f"  > è®€å– [{category}] å¤±æ•—: {sanitize_error_message(e)}")
    print(f"--- [éšæ®µä¸€å®Œæˆ] ç¸½å…±å¾ä¸­å¤®ç¤¾è¼‰å…¥äº† {len(all_articles)} å‰‡æœ‰æ•ˆæ–°è ---")
    return all_articles

def find_keyword_in_cna_news(main_keyword, google_news_title, cna_database):
    primary_keywords = set(main_keyword.split())
    secondary_keywords = set(google_news_title.split())
    all_keywords = primary_keywords.union(secondary_keywords)
    best_match, highest_score = None, 0
    for article in cna_database:
        current_score = 0
        article_title, article_summary = article['title'], article['summary']
        if all(word in article_title for word in primary_keywords): current_score = 100
        elif all(word in article_title for word in all_keywords): current_score = 80
        elif all(word in (article_title + article_summary) for word in primary_keywords): current_score = 10
        if current_score > highest_score:
            highest_score, best_match = current_score, {'title': article['title'], 'link': article['link']}
    return best_match if highest_score >= 80 else None

def generate_curiosity_questions(model, keyword, title):
    print(f"    - [Gemini] æ­£åœ¨ç‚º '{keyword}' ç”Ÿæˆå¥½å¥‡å•é¡Œ...")
    try:
        if not gemini_prompt_template:
            print("âŒ éŒ¯èª¤ï¼šåœ¨ç’°å¢ƒè®Šæ•¸ä¸­æ‰¾ä¸åˆ° 'GEMINI_PROMPT'ã€‚")
            return ['N/A'] * 3
        prompt = gemini_prompt_template.format(keyword=keyword, title=title)
        response = model.generate_content(prompt)
        questions_raw = response.text.strip().split('\n')
        questions = [q.split('. ', 1)[-1].strip() for q in questions_raw if '. ' in q]
        while len(questions) < 3: questions.append('N/A')
        print(f"    - [Gemini] âœ… æˆåŠŸç”Ÿæˆå•é¡Œã€‚")
        return questions[:3]
    except Exception as e:
        # <<< MODIFIED: ä½¿ç”¨æ¸…ç†å‡½å¼ >>>
        print(f"    - [Gemini] âŒ ç”Ÿæˆå•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {sanitize_error_message(e)}")
        return ['N/A'] * 3

def format_email_body_html(matched_items, sheet_url):
    header = "<h1>Google Trends èˆ‡ä¸­å¤®ç¤¾æ–°èæ¯”å°æˆåŠŸé€šçŸ¥</h1>"
    body = "<p>åœ¨æœ¬æ¬¡åŸ·è¡Œä¸­ï¼Œä»¥ä¸‹ç†±é–€é—œéµå­—æˆåŠŸåœ¨ä¸­å¤®ç¤¾æ–°èä¸­æ‰¾åˆ°å°æ‡‰å…§å®¹ï¼Œä¸¦å·²ç”Ÿæˆè®€è€…å¯èƒ½å¥½å¥‡çš„å•é¡Œï¼š</p>"
    table = "<table border='1' style='border-collapse: collapse; width: 100%;'><tr><th style='padding: 8px; text-align: left;'>é—œéµå­—</th><th style='padding: 8px; text-align: left;'>ç›¸é—œæ–°èæ¨™é¡Œ</th><th style='padding: 8px; text-align: left;'>è®€è€…å¥½å¥‡çš„å•é¡Œ</th></tr>"
    for item in matched_items:
        # <<< MODIFIED: å°æ‰€æœ‰å‹•æ…‹å…§å®¹é€²è¡Œ HTML è½‰ç¾© >>>
        keyword_safe = escape_html(item['keyword'])
        cna_link_safe = escape_html(item['cna_link'])
        cna_title_safe = escape_html(item['cna_title'])
        questions_html = "<ul style='margin: 0; padding-left: 20px;'>"
        for q in item.get('questions', []):
            if q != 'N/A':
                questions_html += f"<li>{escape_html(q)}</li>"
        questions_html += "</ul>"
        table += f"<tr><td style='padding: 8px;'>{keyword_safe}</td><td style='padding: 8px;'><a href='{cna_link_safe}'>{cna_title_safe}</a></td><td style='padding: 8px;'>{questions_html}</td></tr>"
    table += "</table>"
    footer = f"<hr><p><a href=\"{escape_html(sheet_url)}\">é»æ­¤æŸ¥çœ‹å®Œæ•´çš„ Google Sheet æ­·å²æ—¥èªŒ</a></p><p style='color: #888;'>è‡ªå‹•åŒ–é€šçŸ¥ï¼Œè«‹å‹¿å›è¦†ã€‚</p>"
    return f"<html><body>{header}{body}{table}{footer}</body></html>"

def send_notification_email(subject, html_body):
    print("--- [éƒµä»¶é€šçŸ¥] æ­£åœ¨æº–å‚™ç™¼é€éƒµä»¶... ---")
    message = MIMEMultipart("alternative")
    message["Subject"], message["From"], message["To"] = f"ğŸ’¡ {subject}", sender_email, receiver_email
    message.attach(MIMEText(html_body, "html"))
    context = ssl.create_default_context()
    try:
        with smtplib.SMTP_SSL("smtp.gmail.com", 465, context=context) as server:
            server.login(sender_email, email_password)
            receiver_email_list = [email.strip() for email in receiver_email.split(',')]
            server.sendmail(sender_email, receiver_email_list, message.as_string())
        print(f"âœ… éƒµä»¶é€šçŸ¥ç™¼é€æˆåŠŸï¼æ”¶ä»¶äºº: {receiver_email_list}")
    except Exception as e:
        # <<< MODIFIED: ä½¿ç”¨æ¸…ç†å‡½å¼ >>>
        print(f"âŒ éƒµä»¶é€šçŸ¥ç™¼é€å¤±æ•—ï¼éŒ¯èª¤: {sanitize_error_message(e)}")

# --- ä¸»é‚è¼¯å‡½å¼ ---
def main():
    print("ğŸš€ [ä¸»æµç¨‹é–‹å§‹] æº–å‚™åŸ·è¡Œæ‰€æœ‰ä»»å‹™...")
    gc = gspread.service_account_from_dict(creds_dict)
    spreadsheet = gc.open_by_key(sheet_id)
    gemini_model = genai.GenerativeModel(GEMINI_MODEL_NAME) # <<< MODIFIED: åˆå§‹åŒ–ä¸€æ¬¡æ¨¡å‹
    
    cna_articles_db = fetch_all_cna_news(CNA_FEEDS)
    print("\n" + "="*20 + " é–‹å§‹ Google Trends åˆ†æèˆ‡äº¤å‰æ¯”å° " + "="*20)
    feed = feedparser.parse("https://trends.google.com/trending/rss?geo=TW")
    
    rss_data, matches_for_email = [], []
    print("--- [éšæ®µäºŒ] é–‹å§‹è™•ç†èˆ‡æ¯”å°æ¯ä¸€å€‹é—œéµå­— ---")
    for entry in feed.entries:
        final_cna_link, final_cna_title = 'ç„¡', ''
        google_news_title = entry.get('ht_news_item_title', '')
        cna_match = find_keyword_in_cna_news(entry.title, google_news_title, cna_articles_db)
        if cna_match:
            final_cna_link, final_cna_title = cna_match['link'], cna_match['title']
        elif 'ä¸­å¤®ç¤¾' in entry.get('ht_news_item_source', ''):
            final_cna_link, final_cna_title = entry.get('ht_news_item_url', 'ç„¡'), entry.get('ht_news_item_title', entry.title)
        
        q1, q2, q3 = 'N/A', 'N/A', 'N/A'
        if final_cna_link != 'ç„¡':
            print(f"  > [æ¯”å°æˆåŠŸ] '{entry.title}' åœ¨ä¸­å¤®ç¤¾æ‰¾åˆ°ç›¸é—œæ–°èï¼")
            questions = generate_curiosity_questions(gemini_model, entry.title, final_cna_title) # <<< MODIFIED: å‚³å…¥æ¨¡å‹ç‰©ä»¶
            q1, q2, q3 = questions
            matches_for_email.append({'keyword': entry.title, 'cna_title': final_cna_title, 'cna_link': final_cna_link, 'questions': questions})
        
        rss_data.append({'é—œéµå­— (Title)': entry.title, 'é ä¼°æœå°‹é‡ (Traffic)': entry.get('ht_approx_traffic', 'N/A'), 'ç™¼å¸ƒæ™‚é–“ (Published)': entry.get('published', 'N/A'), 'ç›¸é—œæ–°èæ¨™é¡Œ (Summary)': f"[{entry.get('ht_news_item_source', 'ç„¡ä¾†æº')}] {entry.get('ht_news_item_title', 'ç„¡')}", 'ç›¸é—œæ–°èé€£çµ': entry.get('ht_news_item_url', 'ç„¡'), 'ä¸­å¤®ç¤¾ç›¸é—œæ–°èç¶²å€': final_cna_link, 'è¶¨å‹¢é€£çµ (Link)': entry.link, 'å¥½å¥‡1': q1, 'å¥½å¥‡2': q2, 'å¥½å¥‡3': q3})

    df_rss = pd.DataFrame(rss_data)
    print("\n--- [éšæ®µä¸‰] æ­£åœ¨æº–å‚™å°‡çµæœå¯«å…¥ Google Sheet ---")
    if not df_rss.empty:
        update_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        write_df_to_worksheet(spreadsheet, SHEET_NAME_DASHBOARD, df_rss, f"æœ€æ–°è¶¨å‹¢å„€è¡¨æ¿ (æ›´æ–°æ™‚é–“: {update_time_str})")
        append_df_to_worksheet(spreadsheet, SHEET_NAME_LOG, df_rss)
        if matches_for_email:
            subject = f"GoogleTrendæ´å¯Ÿï¼š{len(matches_for_email)}å€‹ç†±é–€è¶¨å‹¢èˆ‡è®€è€…æ„åœ–åˆ†æ"
            body = format_email_body_html(matches_for_email, spreadsheet.url)
            send_notification_email(subject, body)
        else:
            print("\n--- [éƒµä»¶é€šçŸ¥] æœ¬æ¬¡åŸ·è¡Œç„¡æˆåŠŸæ¯”å°é …ç›®ï¼Œä¸ç™¼é€éƒµä»¶ã€‚ ---")
    else:
        print("--> Google Trends RSS æœªå›å‚³ä»»ä½•è³‡æ–™ï¼Œæœ¬æ¬¡ä¸æ›´æ–°å·¥ä½œè¡¨ã€‚")

    print("\nğŸ‰ å…¨éƒ¨ä»»å‹™åŸ·è¡Œå®Œç•¢ï¼")
    print(f"ğŸ”— å‰å¾€æŸ¥çœ‹å„€è¡¨æ¿: {spreadsheet.url}")

# --- åŸ·è¡Œç¨‹å¼ ---
if __name__ == "__main__":
    main()
