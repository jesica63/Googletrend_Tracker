# trend_tracker.py (v5.0 - with Smart Search & Enhanced Logic)

# --- å°å…¥æ‰€æœ‰å‡½å¼åº« ---
import pandas as pd
import gspread
from gspread_dataframe import set_with_dataframe
import json
import feedparser
from datetime import datetime
import time
import smtplib
import ssl
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import os
import google.generativeai as genai # å°å…¥ Gemini API å‡½å¼åº«

# --- è¨­å®šæ‰€æœ‰å…¨åŸŸè®Šæ•¸ ---
SHEET_NAME_DASHBOARD = "æœ€æ–°è¶¨å‹¢å„€è¡¨æ¿"
SHEET_NAME_LOG = "å®Œæ•´æ­·å²æ—¥èªŒ"
CNA_FEEDS = { 'æ”¿æ²»': 'https://feeds.feedburner.com/rsscna/politics', 'åœ‹éš›': 'https://feeds.feedburner.com/rsscna/intworld', 'å…©å²¸': 'https://feeds.feedburner.com/rsscna/mainland', 'ç”¢ç¶“è­‰åˆ¸': 'https://feeds.feedburner.com/rsscna/finance', 'ç§‘æŠ€': 'https://feeds.feedburner.com/rsscna/technology', 'ç”Ÿæ´»': 'https://feeds.feedburner.com/rsscna/lifehealth', 'ç¤¾æœƒ': 'https://feeds.feedburner.com/rsscna/social', 'åœ°æ–¹': 'https://feeds.feedburner.com/rsscna/local', 'æ–‡åŒ–': 'https://feeds.feedburner.com/rsscna/culture'}

# --- è®€å–é‡‘é‘°ä¸¦æˆæ¬Š (GitHub Actions ç‰ˆæœ¬) ---
try:
    gcp_key_str = os.environ['GCP_SA_KEY']
    creds_dict = json.loads(gcp_key_str)
    sheet_id = os.environ['G_SHEET_ID']
    sender_email = os.environ['EMAIL_SENDER']
    receiver_email = os.environ['EMAIL_RECEIVER']
    email_password = os.environ['EMAIL_SENDER_APP_PASSWORD']
    gemini_api_key = os.environ['GEMINI_API_KEY']
    print("âœ… æ‰€æœ‰å¯†é‘°å¾ç’°å¢ƒè®Šæ•¸è®€å–æˆåŠŸã€‚")
except KeyError as e:
    print(f"âŒ è®€å–ç’°å¢ƒè®Šæ•¸å¤±æ•—ï¼è«‹ç¢ºèª GitHub Secrets å·²è¨­å®šã€‚ç¼ºå°‘é‡‘é‘°: {e}")
    raise

# --- è¨­å®š Gemini API ---
genai.configure(api_key=gemini_api_key)

# --- å®šç¾©æ‰€æœ‰è¼”åŠ©å‡½å¼ ---
def write_df_to_worksheet(spreadsheet, sheet_name, df, title_text):
    try:
        worksheet = spreadsheet.worksheet(sheet_name)
        worksheet.clear()
    except gspread.WorksheetNotFound:
        worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=len(df)+5, cols=len(df.columns)+1)
    worksheet.update('A1', [[title_text]], value_input_option='USER_ENTERED')
    worksheet.format('A1:G1', {'textFormat': {'bold': True, 'fontSize': 12}})
    set_with_dataframe(worksheet, df, row=3, col=1, include_index=False, resize=True)
    print(f"âœ… æˆåŠŸå°‡è³‡æ–™å¯«å…¥å·¥ä½œè¡¨ '{sheet_name}' (å„€è¡¨æ¿æ¨¡å¼)ã€‚")

def append_df_to_worksheet(spreadsheet, sheet_name, df):
    try:
        worksheet = spreadsheet.worksheet(sheet_name)
    except gspread.WorksheetNotFound:
        worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=len(df.columns)+1)
        worksheet.append_row(df.columns.values.tolist())
    worksheet.append_rows(df.values.tolist())
    print(f"âœ… æˆåŠŸå°‡è³‡æ–™é™„åŠ åˆ°å·¥ä½œè¡¨ '{sheet_name}' (æ—¥èªŒæ¨¡å¼)ã€‚")

def fetch_all_cna_news(feed_urls):
    """
    æŠ“å–æ‰€æœ‰ä¸­å¤®ç¤¾ RSS Feeds çš„æ–°èï¼Œä¸¦éæ¿¾æ‰ç‰¹å®šé—œéµå­—ã€‚
    """
    print("--- [éšæ®µä¸€] æ­£åœ¨é å…ˆæŠ“å–æ‰€æœ‰ä¸­å¤®ç¤¾ RSS Feeds ---")
    all_articles = []
    # --- æ–°å¢ï¼šå®šç¾©æ‚¨ä¸æƒ³çœ‹åˆ°çš„é—œéµå­— ---
    uninteresting_keywords = ['ä»Šå½©', 'å¤§æ¨‚é€', 'ç™¼ç¥¨', 'å¨åŠ›å½©', 'æ¨‚é€å½©'] # æ‚¨å¯ä»¥æ ¹æ“šéœ€è¦ç¹¼çºŒæ·»åŠ 

    for category, url in feed_urls.items():
        try:
            feed = feedparser.parse(url)
            if feed.bozo: print(f"    - [è­¦å‘Š] Feed '{category}' æ ¼å¼å¯èƒ½ä¸å®Œæ•´æˆ–æœ‰èª¤ã€‚")
            
            for entry in feed.entries:
                if hasattr(entry, 'title') and hasattr(entry, 'link'):
                    article_title = entry.title
                    
                    # --- æ–°å¢ï¼šæª¢æŸ¥æ¨™é¡Œæ˜¯å¦åŒ…å«ä¸æ„Ÿèˆˆè¶£çš„é—œéµå­— ---
                    is_uninteresting = False
                    for keyword in uninteresting_keywords:
                        if keyword in article_title:
                            is_uninteresting = True
                            break # æ‰¾åˆ°ä¸€å€‹ä¸æ„Ÿèˆˆè¶£çš„é—œéµå­—å°±åœæ­¢æª¢æŸ¥ï¼Œç›´æ¥è·³éé€™ç¯‡æ–‡ç« 
                    
                    if not is_uninteresting:
                        all_articles.append({'title': article_title, 'summary': entry.get('summary', ''), 'link': entry.link})
                    else:
                        print(f"    - [éæ¿¾] è·³éæ¨™é¡ŒåŒ…å«ä¸æ„Ÿèˆˆè¶£é—œéµå­—çš„æ–°è: \"{article_title}\"")

        except Exception as e:
            print(f"  > è®€å– [{category}] å¤±æ•—: {e}")
            
    print(f"--- [éšæ®µä¸€å®Œæˆ] ç¸½å…±å¾ä¸­å¤®ç¤¾è¼‰å…¥äº† {len(all_articles)} å‰‡æœ‰æ•ˆæ–°è (å·²éæ¿¾ä¸æ„Ÿèˆˆè¶£å…§å®¹) ---")
    return all_articles

# ã€å‡ç´šç‰ˆã€‘æ™ºæ…§æœå°‹å‡½å¼ï¼ŒåŠ å…¥äº†é—œè¯æ€§è©•åˆ†é‚è¼¯
def find_keyword_in_cna_news(main_keyword, google_news_title, cna_database):
    """
    ä½¿ç”¨æ™ºæ…§æ¼”ç®—æ³•åœ¨ä¸­å¤®ç¤¾æ–°èä¸­å°‹æ‰¾é«˜é—œè¯æ€§çš„æ–°èã€‚
    1. å„ªå…ˆåŒ¹é…æ–°èæ¨™é¡Œã€‚
    2. å¾ Google News æ¨™é¡Œä¸­æå–è¼”åŠ©é—œéµå­—ï¼Œæé«˜æº–ç¢ºæ€§ã€‚
    """
    primary_keywords = set(main_keyword.split())
    secondary_keywords = set(google_news_title.split())
    all_keywords = primary_keywords.union(secondary_keywords)

    best_match = None
    highest_score = 0

    for article in cna_database:
        current_score = 0
        article_title = article['title']
        article_summary = article['summary']

        # --- é—œè¯æ€§è©•åˆ†æ©Ÿåˆ¶ ---
        # 1. ä¸»è¦é—œéµå­—å‡ºç¾åœ¨æ¨™é¡Œä¸­ï¼šæœ€é«˜åˆ† (é—œè¯æ€§æ¥µé«˜)
        if all(word in article_title for word in primary_keywords):
            current_score = 100
        
        # 2. æ‰€æœ‰é—œéµå­— (åŒ…å«è¼”åŠ©è©) éƒ½å‡ºç¾åœ¨æ¨™é¡Œä¸­ï¼šæ¬¡é«˜åˆ†
        elif all(word in article_title for word in all_keywords):
            current_score = 80

        # 3. åªæœ‰ä¸»è¦é—œéµå­—å‡ºç¾åœ¨æ‘˜è¦ä¸­ï¼šä½åˆ† (é¿å…èª¤åˆ¤)
        elif all(word in (article_title + article_summary) for word in primary_keywords):
            current_score = 10
        
        if current_score > highest_score:
            highest_score = current_score
            best_match = {'title': article['title'], 'link': article['link']}

    # åªæœ‰åˆ†æ•¸å¤ é«˜ (ä»£è¡¨é—œè¯æ€§å¼·) æ‰å›å‚³çµæœ
    if highest_score >= 80:
        return best_match
    else:
        return None

def generate_curiosity_questions(keyword, title):
    """
    æ ¹æ“šé—œéµå­—å’Œæ–°èæ¨™é¡Œï¼Œä½¿ç”¨ Gemini API ç”Ÿæˆä¸‰å€‹è®€è€…å¥½å¥‡çš„å•é¡Œã€‚
    é€™å€‹å‡½å¼æœƒå¾ç’°å¢ƒè®Šæ•¸è®€å–ç§å¯†çš„ Prompt æŒ‡ä»¤ã€‚
    """
    print(f"    - [Gemini] æ­£åœ¨ç‚º '{keyword}' ç”Ÿæˆå¥½å¥‡å•é¡Œ...")
    try:
        prompt_template = os.environ.get('GEMINI_PROMPT')
        if not prompt_template:
            print("âŒ éŒ¯èª¤ï¼šåœ¨ç’°å¢ƒè®Šæ•¸ä¸­æ‰¾ä¸åˆ° 'GEMINI_PROMPT'ã€‚è«‹æª¢æŸ¥ GitHub Secrets è¨­å®šã€‚")
            return ['N/A', 'N/A', 'N/A']

        prompt = prompt_template.format(keyword=keyword, title=title)
        
        model = genai.GenerativeModel('gemini-2.0-flash-lite')
        response = model.generate_content(prompt)
        
        questions_raw = response.text.strip().split('\n')
        questions = [q.split('. ', 1)[-1].strip() for q in questions_raw if '. ' in q]
        
        while len(questions) < 3:
            questions.append('N/A')
            
        print(f"    - [Gemini] âœ… æˆåŠŸç”Ÿæˆå•é¡Œã€‚")
        return questions[:3]

    except Exception as e:
        print(f"    - [Gemini] âŒ ç”Ÿæˆå•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return ['N/A', 'N/A', 'N/A']

def format_email_body_html(matched_items, sheet_url):
    """å°‡æ¯”å°æˆåŠŸçš„é …ç›®æ ¼å¼åŒ–ç‚º HTML éƒµä»¶å…§å®¹"""
    header = "<h1>Google Trends èˆ‡ä¸­å¤®ç¤¾æ–°èæ¯”å°æˆåŠŸé€šçŸ¥</h1>"
    body = "<p>åœ¨æœ¬æ¬¡åŸ·è¡Œä¸­ï¼Œä»¥ä¸‹ç†±é–€é—œéµå­—æˆåŠŸåœ¨ä¸­å¤®ç¤¾æ–°èä¸­æ‰¾åˆ°å°æ‡‰å…§å®¹ï¼Œä¸¦å·²ç”Ÿæˆè®€è€…å¯èƒ½å¥½å¥‡çš„å•é¡Œï¼š</p>"
    
    table = "<table border='1' style='border-collapse: collapse; width: 100%;'><tr><th style='padding: 8px; text-align: left; width: 20%;'>é—œéµå­—</th><th style='padding: 8px; text-align: left; width: 40%;'>ç›¸é—œæ–°èæ¨™é¡Œ</th><th style='padding: 8px; text-align: left; width: 40%;'>è®€è€…å¥½å¥‡çš„å•é¡Œ</th></tr>"
    
    for item in matched_items:
        questions_html = "<ul style='margin: 0; padding-left: 20px;'>"
        for q in item.get('questions', []):
            if q != 'N/A':
                questions_html += f"<li>{q}</li>"
        questions_html += "</ul>"
        
        table += f"<tr><td style='padding: 8px; vertical-align: top;'>{item['keyword']}</td><td style='padding: 8px; vertical-align: top;'><a href='{item['cna_link']}'>{item['cna_title']}</a></td><td style='padding: 8px; vertical-align: top;'>{questions_html}</td></tr>"
        
    table += "</table>"
    footer = f"""
    <hr>
    <p>
        <a href="{sheet_url}">é»æ­¤æŸ¥çœ‹å®Œæ•´çš„ Google Sheet æ­·å²æ—¥èªŒ (å«æ‰€æœ‰æ¬„ä½)</a>
    </p>
    <p style='color: #888; font-size: 12px;'>
        é€™æ˜¯ä¸€å°è‡ªå‹•åŒ–é€šçŸ¥éƒµä»¶ï¼Œè«‹å‹¿å›è¦†ã€‚
    </p>
    """
    return f"<html><body>{header}{body}{table}{footer}</body></html>"

def send_notification_email(subject, html_body):
    """ç™¼é€éƒµä»¶é€šçŸ¥ï¼Œæ”¯æ´å¤šå€‹æ”¶ä»¶äºº"""
    print("--- [éƒµä»¶é€šçŸ¥] æ­£åœ¨æº–å‚™ç™¼é€éƒµä»¶... ---")
    message = MIMEMultipart("alternative")
    message["Subject"] = f"ğŸ’¡ {subject}" 
    message["From"] = sender_email
    
    # é€™è£¡ receiver_email ä¾ç„¶æ˜¯å®Œæ•´çš„å­—ä¸²ï¼Œç”¨æ–¼éƒµä»¶æ¨™é ­çš„é¡¯ç¤º
    message["To"] = receiver_email 
    
    message.attach(MIMEText(html_body, "html"))
    context = ssl.create_default_context()
    try:
        with smtplib.SMTP_SSL("smtp.gmail.com", 465, context=context) as server:
            server.login(sender_email, email_password)
            
            # ã€é—œéµä¿®æ”¹ã€‘å°‡å­—ä¸²åˆ†å‰²æˆä¸€å€‹ listï¼Œé€™æ‰æ˜¯ sendmail å‡½å¼çœŸæ­£éœ€è¦çš„æ ¼å¼
            receiver_email_list = receiver_email.split(',')
            
            server.sendmail(sender_email, receiver_email_list, message.as_string())
        print(f"âœ… éƒµä»¶é€šçŸ¥ç™¼é€æˆåŠŸï¼æ”¶ä»¶äºº: {receiver_email_list}")
    except Exception as e:
        print(f"âŒ éƒµä»¶é€šçŸ¥ç™¼é€å¤±æ•—ï¼éŒ¯èª¤: {e}")

# --- ä¸»é‚è¼¯å‡½å¼ ---
def main():
    print("ğŸš€ [ä¸»æµç¨‹é–‹å§‹] æº–å‚™åŸ·è¡Œæ‰€æœ‰ä»»å‹™...")
    gc = gspread.service_account_from_dict(creds_dict)
    spreadsheet = gc.open_by_key(sheet_id)
    
    cna_articles_db = fetch_all_cna_news(CNA_FEEDS)

    print("\n" + "="*20 + " é–‹å§‹ Google Trends åˆ†æèˆ‡äº¤å‰æ¯”å° " + "="*20)
    rss_url = "https://trends.google.com/trending/rss?geo=TW"
    feed = feedparser.parse(rss_url)
    
    rss_data = []
    matches_for_email = []

    print("--- [éšæ®µäºŒ] é–‹å§‹è™•ç†èˆ‡æ¯”å°æ¯ä¸€å€‹é—œéµå­— ---")
    for entry in feed.entries:
        final_cna_link = 'ç„¡'
        final_cna_title = ''
        
        q1, q2, q3 = 'N/A', 'N/A', 'N/A'
        
        # ã€ä¿®æ”¹ã€‘ä½¿ç”¨æ–°çš„æ™ºæ…§æœå°‹å‡½å¼ï¼Œå‚³å…¥ä¸»è¦é—œéµå­—å’Œ Google News ä¸Šä¸‹æ–‡æ¨™é¡Œ
        google_news_title = entry.get('ht_news_item_title', '')
        cna_match_from_db = find_keyword_in_cna_news(entry.title, google_news_title, cna_articles_db)
        
        if cna_match_from_db:
            final_cna_link = cna_match_from_db['link']
            final_cna_title = cna_match_from_db['title']
        else:
            # å¦‚æœå…§éƒ¨æœå°‹æ‰¾ä¸åˆ°ï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Google News æ˜¯å¦ç›´æ¥æä¾›äº†ä¸­å¤®ç¤¾çš„é€£çµ
            google_news_source = entry.get('ht_news_item_source', '')
            if 'ä¸­å¤®ç¤¾' in google_news_source or 'CNA' in google_news_source:
                final_cna_link = entry.get('ht_news_item_url', 'ç„¡')
                final_cna_title = entry.get('ht_news_item_title', entry.title)
        
        if final_cna_link != 'ç„¡':
            print(f"  > [æ¯”å°æˆåŠŸ] '{entry.title}' åœ¨ä¸­å¤®ç¤¾æ‰¾åˆ°ç›¸é—œæ–°èï¼")
            
            questions = generate_curiosity_questions(entry.title, final_cna_title)
            q1, q2, q3 = questions
            
            matches_for_email.append({
                'keyword': entry.title, 
                'cna_title': final_cna_title, 
                'cna_link': final_cna_link,
                'questions': questions
            })
        
        rss_data.append({
            'é—œéµå­— (Title)': entry.title, 'é ä¼°æœå°‹é‡ (Traffic)': entry.get('ht_approx_traffic', 'N/A'),
            'ç™¼å¸ƒæ™‚é–“ (Published)': entry.get('published', 'N/A'),
            'ç›¸é—œæ–°èæ¨™é¡Œ (Summary)': f"[{entry.get('ht_news_item_source', 'ç„¡ä¾†æº')}] {entry.get('ht_news_item_title', 'ç„¡ç›´æ¥ç›¸é—œæ–°èå ±å°')}",
            'ç›¸é—œæ–°èé€£çµ': entry.get('ht_news_item_url', 'ç„¡'),
            'ä¸­å¤®ç¤¾ç›¸é—œæ–°èç¶²å€': final_cna_link, 'è¶¨å‹¢é€£çµ (Link)': entry.link,
            'å¥½å¥‡1': q1,
            'å¥½å¥‡2': q2,
            'å¥½å¥‡3': q3,
        })

        # ... (å‰é¢çš„ç¨‹å¼ç¢¼) ...
    df_rss = pd.DataFrame(rss_data)

    print("\n--- [éšæ®µä¸‰] æ­£åœ¨æº–å‚™å°‡çµæœå¯«å…¥ Google Sheet ---")

    # ã€é—œéµä¿®å¾©ã€‘æª¢æŸ¥ DataFrame æ˜¯å¦ç‚ºç©ºï¼Œå¦‚æœä¸ç‚ºç©ºæ‰åŸ·è¡Œå¯«å…¥æ“ä½œ
    if not df_rss.empty:
        update_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        print("--> åµæ¸¬åˆ°æ–°è¶¨å‹¢è³‡æ–™ï¼Œé–‹å§‹å¯«å…¥å·¥ä½œè¡¨...")
        write_df_to_worksheet(spreadsheet, SHEET_NAME_DASHBOARD, df_rss, f"æœ€æ–°è¶¨å‹¢å„€è¡¨æ¿ (æ›´æ–°æ™‚é–“: {update_time_str})")
        append_df_to_worksheet(spreadsheet, SHEET_NAME_LOG, df_rss)
        
        if matches_for_email:
            email_subject = f"GoogleTrendæ´å¯Ÿï¼š{len(matches_for_email)}å€‹ç†±é–€è¶¨å‹¢èˆ‡è®€è€…æ„åœ–åˆ†æ"
            email_body = format_email_body_html(matches_for_email, spreadsheet.url)
            send_notification_email(email_subject, email_body)
        else:
            print("\n--- [éƒµä»¶é€šçŸ¥] æœ¬æ¬¡åŸ·è¡Œç„¡æˆåŠŸæ¯”å°é …ç›®ï¼Œä¸ç™¼é€éƒµä»¶ã€‚ ---")
    else:
        # å¦‚æœ df_rss æ˜¯ç©ºçš„ï¼Œæ‰“å°æç¤ºè¨Šæ¯ï¼Œä¸¦è·³éæ‰€æœ‰å¯«å…¥å’Œéƒµå¯„æ“ä½œ
        print("--> Google Trends RSS æœªå›å‚³ä»»ä½•è³‡æ–™ï¼Œæœ¬æ¬¡ä¸æ›´æ–°å·¥ä½œè¡¨ã€‚")

    print("\nğŸ‰ å…¨éƒ¨ä»»å‹™åŸ·è¡Œå®Œç•¢ï¼")
    print(f"ğŸ”— å‰å¾€æŸ¥çœ‹å„€è¡¨æ¿: {spreadsheet.url}")

# --- åŸ·è¡Œç¨‹å¼ ---
if __name__ == "__main__":
    main()
