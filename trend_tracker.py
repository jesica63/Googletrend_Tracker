"""
ETtoday æ–°èç›£æ§ç¨‹å¼ - å„ªåŒ–ç‰ˆ (V2.0)
åŠŸèƒ½ï¼šç›£æ§ Google Trends é—œéµå­—ï¼Œä¸¦åœ¨ ETtoday æ–°èä¸­å°‹æ‰¾ç›¸é—œå ±å°
å„ªåŒ–ï¼šåŠ å¼·é—œéµå­—æ¯”å°é‚è¼¯ï¼Œæå‡æº–ç¢ºåº¦
ä¿®æ”¹æ—¥æœŸï¼š2025-10-23
"""

# --- å°å…¥æ‰€æœ‰å‡½å¼åº« ---
import pandas as pd
import gspread
from gspread_dataframe import set_with_dataframe
import json
import feedparser
from datetime import datetime
import time
import smtplib
import ssl
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import os
import google.generativeai as genai
import re
from html import unescape

# --- è¨­å®šæ‰€æœ‰å…¨åŸŸè®Šæ•¸ ---
SHEET_NAME_DASHBOARD = "æœ€æ–°è¶¨å‹¢å„€è¡¨æ¿"
SHEET_NAME_LOG = "å®Œæ•´æ­·å²æ—¥èªŒ"

# ETtoday RSS Feeds
ETTODAY_FEEDS = {
    'å³æ™‚': 'https://feeds.feedburner.com/ettoday/newslist',
    'æ”¿æ²»': 'https://feeds.feedburner.com/ettoday/news',
    'è²¡ç¶“': 'https://feeds.feedburner.com/ettoday/finance',
    'åœ‹éš›': 'https://feeds.feedburner.com/ettoday/global',
    'å¤§é™¸': 'https://feeds.feedburner.com/ettoday/china',
    'ç¤¾æœƒ': 'https://feeds.feedburner.com/ettoday/society',
    'ç”Ÿæ´»': 'https://feeds.feedburner.com/ettoday/lifestyle',
    'å½±åŠ‡': 'https://feeds.feedburner.com/ettoday/star',
    'é‹å‹•': 'https://feeds.feedburner.com/ettoday/sport',
    'æ—…éŠ': 'https://feeds.feedburner.com/ettoday/travel',
    '3C': 'https://feeds.feedburner.com/ettoday/teck3c',
    'AI': 'https://www.ettoday.net/rssfeed/ai.xml'
}

# --- è®€å–é‡‘é‘°ä¸¦æˆæ¬Š (GitHub Actions ç‰ˆæœ¬) ---
try:
    gcp_key_str = os.environ['GCP_SA_KEY']
    creds_dict = json.loads(gcp_key_str)
    sheet_id = os.environ['G_SHEET_ID']
    sender_email = os.environ['EMAIL_SENDER']
    receiver_email = os.environ['EMAIL_RECEIVER']
    email_password = os.environ['EMAIL_SENDER_APP_PASSWORD']
    gemini_api_key = os.environ['GEMINI_API_KEY']
    print("âœ… æ‰€æœ‰å¯†é‘°å¾ç’°å¢ƒè®Šæ•¸è®€å–æˆåŠŸã€‚")
except KeyError as e:
    print(f"âŒ è®€å–ç’°å¢ƒè®Šæ•¸å¤±æ•—ï¼è«‹ç¢ºèª GitHub Secrets å·²è¨­å®šã€‚ç¼ºå°‘é‡‘é‘°: {e}")
    raise

# --- è¨­å®š Gemini API ---
genai.configure(api_key=gemini_api_key)

# --- å®šç¾©æ‰€æœ‰è¼”åŠ©å‡½å¼ ---

def clean_html_content(html_text):
    """
    æ¸…ç† HTML æ¨™ç±¤ï¼Œæå–ç´”æ–‡å­—å…§å®¹
    ETtoday çš„ summary/description åŒ…å« <img> ç­‰ HTML æ¨™ç±¤ï¼Œéœ€è¦æ¸…ç†
    """
    if not html_text:
        return ""

    # ç§»é™¤æ‰€æœ‰ HTML æ¨™ç±¤
    text = re.sub(r'<[^>]+>', '', html_text)

    # è§£ç¢¼ HTML å¯¦é«”ï¼ˆå¦‚ &nbsp;, &quot; ç­‰ï¼‰
    text = unescape(text)

    # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å­—å…ƒ
    text = ' '.join(text.split())

    return text


def write_df_to_worksheet(spreadsheet, sheet_name, df, title_text):
    try:
        worksheet = spreadsheet.worksheet(sheet_name)
        worksheet.clear()
    except gspread.WorksheetNotFound:
        worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=len(df)+5, cols=len(df.columns)+1)
    worksheet.update('A1', [[title_text]], value_input_option='USER_ENTERED')
    worksheet.format('A1:G1', {'textFormat': {'bold': True, 'fontSize': 12}})
    set_with_dataframe(worksheet, df, row=3, col=1, include_index=False, resize=True)
    print(f"âœ… æˆåŠŸå°‡è³‡æ–™å¯«å…¥å·¥ä½œè¡¨ '{sheet_name}' (å„€è¡¨æ¿æ¨¡å¼)ã€‚")

def append_df_to_worksheet(spreadsheet, sheet_name, df):
    try:
        worksheet = spreadsheet.worksheet(sheet_name)
    except gspread.WorksheetNotFound:
        worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=len(df.columns)+1)
        worksheet.append_row(df.columns.values.tolist())
    worksheet.append_rows(df.values.tolist())
    print(f"âœ… æˆåŠŸå°‡è³‡æ–™é™„åŠ åˆ°å·¥ä½œè¡¨ '{sheet_name}' (æ—¥èªŒæ¨¡å¼)ã€‚")

def fetch_all_ettoday_news(feed_urls):
    """
    æŠ“å–æ‰€æœ‰ ETtoday RSS Feeds çš„æ–°èï¼Œä¸¦éæ¿¾æ‰ç‰¹å®šé—œéµå­—ã€‚
    """
    print("--- [éšæ®µä¸€] æ­£åœ¨é å…ˆæŠ“å–æ‰€æœ‰ ETtoday RSS Feeds ---")
    all_articles = []

    # å®šç¾©æ‚¨ä¸æƒ³çœ‹åˆ°çš„é—œéµå­—
    uninteresting_keywords = ['ä»Šå½©', 'å¤§æ¨‚é€', 'ç™¼ç¥¨', 'å¨åŠ›å½©', 'æ¨‚é€å½©']

    for category, url in feed_urls.items():
        try:
            feed = feedparser.parse(url)
            if feed.bozo:
                print(f"    - [è­¦å‘Š] Feed '{category}' æ ¼å¼å¯èƒ½ä¸å®Œæ•´æˆ–æœ‰èª¤ã€‚")

            for entry in feed.entries:
                if hasattr(entry, 'title') and hasattr(entry, 'link'):
                    article_title = entry.title

                    # æª¢æŸ¥æ¨™é¡Œæ˜¯å¦åŒ…å«ä¸æ„Ÿèˆˆè¶£çš„é—œéµå­—
                    is_uninteresting = False
                    for keyword in uninteresting_keywords:
                        if keyword in article_title:
                            is_uninteresting = True
                            break

                    if not is_uninteresting:
                        # ETtoday çš„ summary åŒ…å« HTMLï¼Œéœ€è¦æ¸…ç†
                        raw_summary = entry.get('summary', entry.get('description', ''))
                        clean_summary = clean_html_content(raw_summary)

                        all_articles.append({
                            'title': article_title,
                            'summary': clean_summary,
                            'link': entry.link
                        })
                    else:
                        print(f"    - [éæ¿¾] è·³éæ¨™é¡ŒåŒ…å«ä¸æ„Ÿèˆˆè¶£é—œéµå­—çš„æ–°è: \"{article_title}\"")

        except Exception as e:
            print(f"  > è®€å– [{category}] å¤±æ•—: {e}")

    print(f"--- [éšæ®µä¸€å®Œæˆ] ç¸½å…±å¾ ETtoday è¼‰å…¥äº† {len(all_articles)} å‰‡æœ‰æ•ˆæ–°è (å·²éæ¿¾ä¸æ„Ÿèˆˆè¶£å…§å®¹) ---")
    return all_articles

def find_keyword_in_ettoday_news(main_keyword, google_news_title, ettoday_database):
    """
    ã€V2.0 - å‡ç´šç‰ˆæ¼”ç®—æ³•ã€‘åœ¨ ETtoday æ–°èä¸­å°‹æ‰¾é«˜é—œè¯æ€§çš„æ–°èã€‚
    æ­¤ç‰ˆæœ¬å„ªåŒ–äº†è©•åˆ†é‚è¼¯ï¼Œå„ªå…ˆè™•ç†å®Œæ•´è©çµ„åŒ¹é…ï¼Œä»¥æé«˜æº–ç¢ºæ€§ã€‚
    """
    # 1. æº–å‚™ä¸»è¦èˆ‡æ¬¡è¦é—œéµå­—
    # ä¸»è¦é—œéµå­— (Google Trend)
    primary_keywords_set = set(main_keyword.split())
    # è¼”åŠ©é—œéµå­— (ä¾†è‡ª Google News æ¨™é¡Œ)
    secondary_keywords_set = set(google_news_title.split())
    all_keywords_set = primary_keywords_set.union(secondary_keywords_set)

    best_match = None
    highest_score = 0

    for article in ettoday_database:
        current_score = 0
        article_title = article['title']
        article_summary = article['summary']

        # --- ã€å…¨æ–°ã€‘é—œè¯æ€§è©•åˆ†æ©Ÿåˆ¶ ---
        # ç­‰ç´š 1 (æœ€é«˜åˆ†): å®Œæ•´çš„ä¸»è¦é—œéµå­—è©çµ„ï¼ŒåŸå°ä¸å‹•åœ°å‡ºç¾åœ¨æ¨™é¡Œä¸­ã€‚
        # é€™æ˜¯æœ€ç†æƒ³ã€æœ€æº–ç¢ºçš„åŒ¹é…ã€‚
        # ç¯„ä¾‹: Trend="iPhone 16 ç™¼è¡¨", æ¨™é¡Œ="...iPhone 16 ç™¼è¡¨æœƒæ™‚é–“ç¢ºå®š..."
        if main_keyword in article_title:
            current_score = 120

        # ç­‰ç´š 2: æ‹†åˆ†å¾Œçš„ä¸»è¦é—œéµå­—ï¼Œå…¨éƒ¨å‡ºç¾åœ¨æ¨™é¡Œä¸­ã€‚
        # ä½œç‚ºå‚™æ¡ˆï¼Œè™•ç†é †åºé¡›å€’æˆ–ä¸­é–“æœ‰å…¶ä»–å­—çš„æƒ…æ³ã€‚
        # ç¯„ä¾‹: Trend="é¢±é¢¨è·¯å¾‘", æ¨™é¡Œ="...æœ€æ–°é¢±é¢¨å‹•æ…‹ï¼Œè·¯å¾‘ååŒ—..."
        elif all(word in article_title for word in primary_keywords_set):
            current_score = 100

        # ç­‰ç´š 3: åŒ…å«è¼”åŠ©é—œéµå­—ï¼Œæ‰€æœ‰é—œéµå­—éƒ½å‡ºç¾åœ¨æ¨™é¡Œä¸­ã€‚
        # æ“´å¤§æœå°‹ç¯„åœï¼Œä½†æ¬Šé‡è¼ƒä½ã€‚
        elif all(word in article_title for word in all_keywords_set):
            current_score = 80

        # ç­‰ç´š 4: å®Œæ•´çš„ä¸»è¦é—œéµå­—è©çµ„ï¼Œå‡ºç¾åœ¨æ‘˜è¦ (summary) ä¸­ã€‚
        # æ¨™é¡Œæ²’æåˆ°ï¼Œä½†å…§æ–‡é«˜åº¦ç›¸é—œã€‚
        elif main_keyword in article_summary:
            current_score = 60

        # ç­‰ç´š 5: æ‹†åˆ†å¾Œçš„ä¸»è¦é—œéµå­—ï¼Œå‡ºç¾åœ¨æ¨™é¡Œ+æ‘˜è¦ä¸­ã€‚
        # æœ€ä½æ¨™æº–ï¼Œé¿å…èª¤åˆ¤ï¼Œåˆ†æ•¸è¨­å®šåœ¨é–¾å€¼ä»¥ä¸‹ã€‚
        elif all(word in (article_title + article_summary) for word in primary_keywords_set):
            current_score = 20

        # æ›´æ–°æœ€é«˜åˆ†çš„åŒ¹é…çµæœ
        if current_score > highest_score:
            highest_score = current_score
            best_match = {'title': article['title'], 'link': article['link']}

    # åªæœ‰åˆ†æ•¸å¤ é«˜ (ä»£è¡¨é—œè¯æ€§å¼·) æ‰å›å‚³çµæœ
    # å°‡é–¾å€¼è¨­å®šç‚º 75ï¼Œå¢åŠ åŒ¹é…ç‡ (å¯æ¥å—ç­‰ç´š3çš„éƒ¨åˆ†åŒ¹é…)
    if highest_score >= 75:
        print(f"      - [æ™ºæ…§æœå°‹] æ‰¾åˆ°é«˜é—œè¯åŒ¹é… (åˆ†æ•¸: {highest_score}) -> {best_match['title']}")
        return best_match
    else:
        return None

def generate_curiosity_questions(keyword, title):
    """
    æ ¹æ“šé—œéµå­—å’Œæ–°èæ¨™é¡Œï¼Œä½¿ç”¨ Gemini API ç”Ÿæˆä¸‰å€‹è®€è€…å¥½å¥‡çš„å•é¡Œã€‚
    é€™å€‹å‡½å¼æœƒå¾ç’°å¢ƒè®Šæ•¸è®€å–ç§å¯†çš„ Prompt æŒ‡ä»¤ã€‚
    """
    print(f" - [Gemini] æ­£åœ¨ç‚º '{keyword}' ç”Ÿæˆå¥½å¥‡å•é¡Œ...")
    try:
        prompt_template = os.environ.get('GEMINI_PROMPT')
        if not prompt_template:
            print("âŒ éŒ¯èª¤ï¼šåœ¨ç’°å¢ƒè®Šæ•¸ä¸­æ‰¾ä¸åˆ° 'GEMINI_PROMPT'ã€‚è«‹æª¢æŸ¥ GitHub Secrets è¨­å®šã€‚")
            return ['N/A', 'N/A', 'N/A']

        prompt = prompt_template.format(keyword=keyword, title=title)

        model = genai.GenerativeModel('gemini-2.0-flash-lite')
        response = model.generate_content(prompt)

        questions_raw = response.text.strip().split('\n')
        questions = [q.split('. ', 1)[-1].strip() for q in questions_raw if '. ' in q]

        while len(questions) < 3:
            questions.append('N/A')

        print(f"    - [Gemini] âœ… æˆåŠŸç”Ÿæˆå•é¡Œã€‚")
        return questions[:3]

    except Exception as e:
        print(f"    - [Gemini] âŒ ç”Ÿæˆå•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return ['N/A', 'N/A', 'N/A']

def format_email_body_html(matched_items, sheet_url):
    """å°‡æ¯”å°æˆåŠŸçš„é …ç›®æ ¼å¼åŒ–ç‚º HTML éƒµä»¶å…§å®¹"""
    header = "<h1>Google Trends èˆ‡ ETtoday æ–°èæ¯”å°æˆåŠŸé€šçŸ¥</h1>"
    body = "<p>åœ¨æœ¬æ¬¡åŸ·è¡Œä¸­ï¼Œä»¥ä¸‹ç†±é–€é—œéµå­—æˆåŠŸåœ¨ ETtoday æ–°èä¸­æ‰¾åˆ°å°æ‡‰å…§å®¹ï¼Œä¸¦å·²ç”Ÿæˆè®€è€…å¯èƒ½å¥½å¥‡çš„å•é¡Œï¼š</p>"

    table = "<table border='1' style='border-collapse: collapse; width: 100%;'><tr><th style='padding: 8px; text-align: left; width: 20%;'>é—œéµå­—</th><th style='padding: 8px; text-align: left; width: 40%;'>ç›¸é—œæ–°èæ¨™é¡Œ</th><th style='padding: 8px; text-align: left; width: 40%;'>è®€è€…å¥½å¥‡çš„å•é¡Œ</th></tr>"

    for item in matched_items:
        questions_html = "<ul style='margin: 0; padding-left: 20px;'>"
        for q in item.get('questions', []):
            if q != 'N/A':
                questions_html += f"<li>{q}</li>"
        questions_html += "</ul>"

        table += f"<tr><td style='padding: 8px; vertical-align: top;'>{item['keyword']}</td><td style='padding: 8px; vertical-align: top;'><a href='{item['news_link']}'>{item['news_title']}</a></td><td style='padding: 8px; vertical-align: top;'>{questions_html}</td></tr>"

    table += "</table>"
    footer = f"""
    <hr>
    <p>
        <a href="{sheet_url}">é»æ­¤æŸ¥çœ‹å®Œæ•´çš„ Google Sheet æ­·å²æ—¥èªŒ (å«æ‰€æœ‰æ¬„ä½)</a>
    </p>
    <p style='color: #888; font-size: 12px;'>
        é€™æ˜¯ä¸€å°è‡ªå‹•åŒ–é€šçŸ¥éƒµä»¶ï¼Œè«‹å‹¿å›è¦†ã€‚
    </p>
    """
    return f"<html><body>{header}{body}{table}{footer}</body></html>"

def send_notification_email(subject, html_body):
    """ç™¼é€éƒµä»¶é€šçŸ¥ï¼Œæ”¯æ´å¤šå€‹æ”¶ä»¶äºº"""
    print("--- [éƒµä»¶é€šçŸ¥] æ­£åœ¨æº–å‚™ç™¼é€éƒµä»¶... ---")
    message = MIMEMultipart("alternative")
    message["Subject"] = f"ğŸ’¡ {subject}" 
    message["From"] = sender_email
    
    # é€™è£¡ receiver_email ä¾ç„¶æ˜¯å®Œæ•´çš„å­—ä¸²ï¼Œç”¨æ–¼éƒµä»¶æ¨™é ­çš„é¡¯ç¤º
    message["To"] = receiver_email 
    
    message.attach(MIMEText(html_body, "html"))
    context = ssl.create_default_context()
    try:
        with smtplib.SMTP_SSL("smtp.gmail.com", 465, context=context) as server:
            server.login(sender_email, email_password)
            
            # ã€é—œéµä¿®æ”¹ã€‘å°‡å­—ä¸²åˆ†å‰²æˆä¸€å€‹ listï¼Œé€™æ‰æ˜¯ sendmail å‡½å¼çœŸæ­£éœ€è¦çš„æ ¼å¼
            receiver_email_list = receiver_email.split(',')
            
            server.sendmail(sender_email, receiver_email_list, message.as_string())
        print(f"âœ… éƒµä»¶é€šçŸ¥ç™¼é€æˆåŠŸï¼æ”¶ä»¶äºº: {receiver_email_list}")
    except Exception as e:
        print(f"âŒ éƒµä»¶é€šçŸ¥ç™¼é€å¤±æ•—ï¼éŒ¯èª¤: {e}")

# --- ä¸»é‚è¼¯å‡½å¼ ---

def main():
    print("ğŸš€ [ä¸»æµç¨‹é–‹å§‹] æº–å‚™åŸ·è¡Œæ‰€æœ‰ä»»å‹™...")
    gc = gspread.service_account_from_dict(creds_dict)
    spreadsheet = gc.open_by_key(sheet_id)

    # æŠ“å–æ‰€æœ‰ ETtoday æ–°è
    ettoday_articles_db = fetch_all_ettoday_news(ETTODAY_FEEDS)

    print("\n" + "="*20 + " é–‹å§‹ Google Trends åˆ†æèˆ‡äº¤å‰æ¯”å° " + "="*20)
    rss_url = "https://trends.google.com/trending/rss?geo=TW"
    feed = feedparser.parse(rss_url)

    rss_data = []
    matches_for_email = []

    print("--- [éšæ®µäºŒ] é–‹å§‹è™•ç†èˆ‡æ¯”å°æ¯ä¸€å€‹é—œéµå­— ---")
    for entry in feed.entries:
        final_news_link = 'ç„¡'
        final_news_title = ''

        q1, q2, q3 = 'N/A', 'N/A', 'N/A'

        # ä½¿ç”¨å„ªåŒ–ç‰ˆæ™ºæ…§æœå°‹å‡½å¼ï¼Œå‚³å…¥ä¸»è¦é—œéµå­—å’Œ Google News ä¸Šä¸‹æ–‡æ¨™é¡Œ
        google_news_title = entry.get('ht_news_item_title', '')
        ettoday_match_from_db = find_keyword_in_ettoday_news(entry.title, google_news_title, ettoday_articles_db)

        if ettoday_match_from_db:
            final_news_link = ettoday_match_from_db['link']
            final_news_title = ettoday_match_from_db['title']
        else:
            # å¦‚æœå…§éƒ¨æœå°‹æ‰¾ä¸åˆ°ï¼Œå†æª¢æŸ¥ä¸€æ¬¡ Google News æ˜¯å¦ç›´æ¥æä¾›äº† ETtoday çš„é€£çµ
            google_news_source = entry.get('ht_news_item_source', '')
            # æª¢æŸ¥ä¾†æºæ˜¯å¦ç‚º ETtoday
            if 'ETtoday' in google_news_source or 'ETtodayæ–°èé›²' in google_news_source or 'ettoday' in google_news_source.lower():
                final_news_link = entry.get('ht_news_item_url', 'ç„¡')
                final_news_title = entry.get('ht_news_item_title', entry.title)

        if final_news_link != 'ç„¡':
            print(f"  > [æ¯”å°æˆåŠŸ] '{entry.title}' åœ¨ ETtoday æ‰¾åˆ°ç›¸é—œæ–°èï¼")

            questions = generate_curiosity_questions(entry.title, final_news_title)
            q1, q2, q3 = questions

            matches_for_email.append({
                'keyword': entry.title,
                'news_title': final_news_title,
                'news_link': final_news_link,
                'questions': questions
            })

        rss_data.append({
            'é—œéµå­— (Title)': entry.title,
            'é ä¼°æœå°‹é‡ (Traffic)': entry.get('ht_approx_traffic', 'N/A'),
            'ç™¼å¸ƒæ™‚é–“ (Published)': entry.get('published', 'N/A'),
            'ç›¸é—œæ–°èæ¨™é¡Œ (Summary)': f"[{entry.get('ht_news_item_source', 'ç„¡ä¾†æº')}] {entry.get('ht_news_item_title', 'ç„¡ç›´æ¥ç›¸é—œæ–°èå ±å°')}",
            'ç›¸é—œæ–°èé€£çµ': entry.get('ht_news_item_url', 'ç„¡'),
            'ETtodayç›¸é—œæ–°èç¶²å€': final_news_link,
            'è¶¨å‹¢é€£çµ (Link)': entry.link,
            'å¥½å¥‡1': q1,
            'å¥½å¥‡2': q2,
            'å¥½å¥‡3': q3,
        })

    df_rss = pd.DataFrame(rss_data)

    print("\n--- [éšæ®µä¸‰] æ­£åœ¨æº–å‚™å°‡çµæœå¯«å…¥ Google Sheet ---")

    # æª¢æŸ¥ DataFrame æ˜¯å¦ç‚ºç©ºï¼Œå¦‚æœä¸ç‚ºç©ºæ‰åŸ·è¡Œå¯«å…¥æ“ä½œ
    if not df_rss.empty:
        update_time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        print("--> åµæ¸¬åˆ°æ–°è¶¨å‹¢è³‡æ–™ï¼Œé–‹å§‹å¯«å…¥å·¥ä½œè¡¨...")
        write_df_to_worksheet(spreadsheet, SHEET_NAME_DASHBOARD, df_rss, f"æœ€æ–°è¶¨å‹¢å„€è¡¨æ¿ (æ›´æ–°æ™‚é–“: {update_time_str})")
        append_df_to_worksheet(spreadsheet, SHEET_NAME_LOG, df_rss)

        if matches_for_email:
            email_subject = f"GoogleTrendæ´å¯Ÿï¼š{len(matches_for_email)}å€‹ç†±é–€è¶¨å‹¢èˆ‡è®€è€…æ„åœ–åˆ†æ (ETtoday)"
            email_body = format_email_body_html(matches_for_email, spreadsheet.url)
            send_notification_email(email_subject, email_body)
        else:
            print("\n--- [éƒµä»¶é€šçŸ¥] æœ¬æ¬¡åŸ·è¡Œç„¡æˆåŠŸæ¯”å°é …ç›®ï¼Œä¸ç™¼é€éƒµä»¶ã€‚ ---")
    else:
        print("--> Google Trends RSS æœªå›å‚³ä»»ä½•è³‡æ–™ï¼Œæœ¬æ¬¡ä¸æ›´æ–°å·¥ä½œè¡¨ã€‚")

    print("\nğŸ‰ å…¨éƒ¨ä»»å‹™åŸ·è¡Œå®Œç•¢ï¼")
    print(f"ğŸ”— å‰å¾€æŸ¥çœ‹å„€è¡¨æ¿: {spreadsheet.url}")


# --- åŸ·è¡Œç¨‹å¼ ---
if __name__ == "__main__":
    main()
